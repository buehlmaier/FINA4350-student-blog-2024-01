<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="Group ESG & Volatility" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group ESG & Volatility, Progress Report, " />

<meta property="og:title" content="Review &amp; Reflection Part 1 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/review-reflection-part-1-esg-news-and-stock-volatility-by-group-esg-volatility.html" />
<meta property="og:description" content="For this blog post, we will provide a cumulative review and reflection on our project, &#39;ESG &amp; Volatility,&#39; specifically on the Data Collection and Text Preprocessing and Cleaning portion of our project. Data Collection: Our project aims to explore how stock price volatility in a company reacts to positive and negative …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2024" />
<meta property="og:article:author" content="Group ESG & Volatility" />
<meta property="og:article:published_time" content="2024-04-30T19:12:00+08:00" />
<meta name="twitter:title" content="Review &amp; Reflection Part 1 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;) ">
<meta name="twitter:description" content="For this blog post, we will provide a cumulative review and reflection on our project, &#39;ESG &amp; Volatility,&#39; specifically on the Data Collection and Text Preprocessing and Cleaning portion of our project. Data Collection: Our project aims to explore how stock price volatility in a company reacts to positive and negative …">

        <title>Review &amp; Reflection Part 1 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;)  · FINA4350 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/"><span class=site-name>FINA4350 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2024-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/review-reflection-part-1-esg-news-and-stock-volatility-by-group-esg-volatility.html">
                Review & Reflection Part 1 - ESG News and Stock Volatility (by Group "ESG & Volatility")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>For this blog post, we will provide a cumulative review and reflection on our project, 'ESG &amp; Volatility,' specifically on the Data Collection and Text Preprocessing and Cleaning portion of our project. </p>
<h2>Data Collection:</h2>
<p>Our project aims to explore how stock price volatility in a company reacts to positive and negative Environmental, Social, and Governance (ESG) news. Specifically, we want to assess whether stock prices are more sensitive to positive or negative ESG sentiments. To achieve this, we utilized Natural Language Processing (NLP) and text analytics to analyze the relationship between ESG news sentiment and stock price movements.</p>
<p>Initially, selecting a focus company for our research was challenging. We reviewed over 20 companies listed on the NASDAQ (i.e., MSFT, AAPL) and S&amp;P 500 (i.e., AMZN, GOOGL) examining their recent positive and negative events. Ultimately, we chose Starbucks Corp (SBUX) because it demonstrated a clear distinction between positive and negative ESG-related events, making it an ideal candidate for our study.</p>
<p>We dedicated a significant portion of our project timeline to selecting a focus company, which caused us to accelerate the remaining tasks to meet our final deadline. Additionally, as beginner programmers, we spent considerable time learning to code while progressing through our project.</p>
<p>Once we selected our focus company, we began compiling URLs of news articles related to positive and negative ESG events to scrape text data for sentiment analysis using Javascript and Python. This phase presented several challenges and required multiple iterations. Initially, we used BeautifulSoup to filter through the URLs, but it scraped all text from the news websites, not just the news content. As a result, we attempted to combine Selenium with BeautifulSoup to target only the news text but encountered numerous errors due to difficulties in integrating these two packages. Ultimately, after consulting with our professor, we decided to switch to Newspaper3k, a package specifically designed for scraping news text data, which proved more suitable for our project. </p>
<div class="highlight"><pre><span></span><code><span class="kd">var</span><span class="w"> </span><span class="nx">links</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">document</span><span class="p">.</span><span class="nx">getElementsByTagName</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">);</span>
<span class="kd">var</span><span class="w"> </span><span class="nx">linksArr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[];</span>

<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kd">var</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nx">links</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span><span class="w"> </span><span class="nx">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">links</span><span class="p">[</span><span class="nx">i</span><span class="p">].</span><span class="nx">ping</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>
<span class="w">     </span><span class="o">!</span><span class="nx">links</span><span class="p">[</span><span class="nx">i</span><span class="p">].</span><span class="nx">href</span><span class="p">.</span><span class="nx">includes</span><span class="p">(</span><span class="s1">&#39;google&#39;</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">     </span><span class="nx">linksArr</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="s1">&#39;&lt;p&gt;&#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">links</span><span class="p">[</span><span class="nx">i</span><span class="p">].</span><span class="nx">href</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;&lt;/p&gt;&#39;</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="kd">var</span><span class="w"> </span><span class="nx">newWindowContent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">linksArr</span><span class="p">.</span><span class="nx">join</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">);</span>
<span class="kd">var</span><span class="w"> </span><span class="nx">newWindow</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">window</span><span class="p">.</span><span class="nx">open</span><span class="p">();</span>
<span class="nx">newWindow</span><span class="p">.</span><span class="nb">document</span><span class="p">.</span><span class="nx">write</span><span class="p">(</span><span class="nx">newWindowContent</span><span class="p">);</span>
<span class="nx">newWindow</span><span class="p">.</span><span class="nb">document</span><span class="p">.</span><span class="nx">close</span><span class="p">();</span>
</code></pre></div>

<p>If we were to restart this process, it would be more beneficial to select news sources with a consistent format rather than using various outlets with different formats. Opting for articles from a single database, such as Factiva, would streamline the data collection and web scraping stages of our project. Additionally, during our initial attempt, we encountered several URLs with firewalls or subscription requirements that hindered our scraping efforts, as the packages we used were unable to bypass these barriers. A consistent format and source would also mitigate these issues, allowing for smoother data collection. </p>
<p>Moreover, considering the large number of news article URLs we handled, it would have been more efficient to save these URLs in a CSV file. Parsing through the URLs from the CSV file would have allowed for a more organized and condensed overview, facilitating easier management and access during our project. However, we did manage to save the extracted details from each positive and negative ESG event into CSV files. This step was crucial for data preprocessing, allowing us to organize and analyze the information more effectively.</p>
<p>Below is a snippet of our code used to handle the large number of news article URLs and extract details from each positive ESG event. We applied a similar process for the negative ESG events, effectively managing and analyzing data from both types of events:</p>
<div class="highlight"><pre><span></span><code><span class="n">pip</span> <span class="n">install</span> <span class="n">newspaper3k</span> <span class="n">pandas</span>

<span class="kn">from</span> <span class="nn">newspaper</span> <span class="kn">import</span> <span class="n">Article</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span> <span class="s1">&#39;...&#39;</span> <span class="p">]</span>

<span class="k">def</span> <span class="nf">extract_details</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">article</span> <span class="o">=</span> <span class="n">Article</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">article</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
        <span class="n">article</span><span class="o">.</span><span class="n">parse</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;link&#39;</span><span class="p">:</span> <span class="n">url</span><span class="p">,</span>
            <span class="s1">&#39;title&#39;</span><span class="p">:</span> <span class="n">article</span><span class="o">.</span><span class="n">title</span><span class="p">,</span>
            <span class="s1">&#39;source&#39;</span><span class="p">:</span> <span class="n">article</span><span class="o">.</span><span class="n">source_url</span><span class="p">,</span>
            <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">article</span><span class="o">.</span><span class="n">publish_date</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">article</span><span class="o">.</span><span class="n">publish_date</span> <span class="k">else</span> <span class="s1">&#39;No Date Found&#39;</span><span class="p">,</span>
            <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">article</span><span class="o">.</span><span class="n">text</span>
        <span class="p">}</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to process </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>


<span class="c1"># List to store results</span>
<span class="n">news_results</span> <span class="o">=</span> <span class="p">[]</span>


<span class="c1"># Process each URL</span>
<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">extract_details</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
        <span class="n">news_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>


<span class="c1"># Save the results to a CSV file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;positive_news_data.csv&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csv_file</span><span class="p">:</span>
    <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;link&quot;</span><span class="p">,</span> <span class="s2">&quot;title&quot;</span><span class="p">,</span> <span class="s2">&quot;source&quot;</span><span class="p">,</span> <span class="s2">&quot;date&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">]</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span><span class="n">csv_file</span><span class="p">,</span> <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">)</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writerows</span><span class="p">(</span><span class="n">news_results</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data saved to positive_news_data.csv&quot;</span><span class="p">)</span>
</code></pre></div>

<h2>Text Preprocessing and Cleaning:</h2>
<p>After we scraped the news articles, we moved on to text preprocessing. For text cleaning, we converted all text into lowercase and removed unnecessary non-word characters like punctuations in order to remove noise. Initially, we removed all punctuation marks; however, we discovered that this approach also removes the dash, combining the words that were separated by dashes into a single word. For example, 'company-operated' was combined into one word 'companyoperated' when the dash was removed, which has the potential to be misinterpreted when we run sentiment analysis. Therefore, we adjusted our code to remove all punctuation marks except for the dash as well as the exclamation mark since exclamation marks could convey sentiment. Below is the code snippet of our adjusted code:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Define the clean_text() function</span>
<span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
   <span class="n">cleaned_text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[^a-zA-Z\s!-]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
   <span class="n">cleaned_text</span> <span class="o">=</span> <span class="n">cleaned_text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
   <span class="k">return</span> <span class="n">cleaned_text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</code></pre></div>

<p>Yet, we still faced some limitations of the outcome and one example is that 'U.S.' was converted to 'us' when we removed the punctuations. This could completely change the meaning of the word and hence, limit the reliability of our results in subsequent stages of sentiment analysis. We also acknowledged some other limitations in our outcomes in further steps of text preprocessing. For instance, when we attempted stemming, we realized that stemming is not always perfect and can remove word components, leaving behind stems that are grammatically incorrect. Overall, our attempts in text preprocessing have taught us about the complexities involved in preparing for language analysis and how difficult it is to clean the text data perfectly, especially when dealing with a substantial volume of text data that cannot be manually cleaned individually. We also learned the importance of finding a balance between completeness and practicality in text preprocessing. While it is important to aim for the best possible data cleaning, we should also consider the feasibility and efficiency of the data cleaning methods being used. </p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-04-30T19:12:00+08:00">Tue 30 April 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html#group-esg-volatility-ref">Group ESG & Volatility
                    <span class="superscript">3</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2024-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>