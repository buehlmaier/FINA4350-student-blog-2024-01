<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="Group ESG & Volatility" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group ESG & Volatility, Progress Report, " />

<meta property="og:title" content="Review &amp; Reflection Part 2 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/review-reflection-part-2-esg-news-and-stock-volatility-by-group-esg-volatility.html" />
<meta property="og:description" content="For this blog post, we will provide a cumulative review and reflection on our project, &#39;ESG &amp; Volatility,&#39; specifically on the Sentiment Analysis and Stock Volatility portion of our project. Sentiment Analysis: Using the cleaned text data, we then conducted sentiment analysis on the news articles by using Vader from NLTK …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2024" />
<meta property="og:article:author" content="Group ESG & Volatility" />
<meta property="og:article:published_time" content="2024-04-29T22:07:00+08:00" />
<meta name="twitter:title" content="Review &amp; Reflection Part 2 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;) ">
<meta name="twitter:description" content="For this blog post, we will provide a cumulative review and reflection on our project, &#39;ESG &amp; Volatility,&#39; specifically on the Sentiment Analysis and Stock Volatility portion of our project. Sentiment Analysis: Using the cleaned text data, we then conducted sentiment analysis on the news articles by using Vader from NLTK …">

        <title>Review &amp; Reflection Part 2 - ESG News and Stock Volatility (by Group &#34;ESG &amp; Volatility&#34;)  · FINA4350 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/"><span class=site-name>FINA4350 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2024-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/review-reflection-part-2-esg-news-and-stock-volatility-by-group-esg-volatility.html">
                Review & Reflection Part 2 - ESG News and Stock Volatility (by Group "ESG & Volatility")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>For this blog post, we will provide a cumulative review and reflection on our project, 'ESG &amp; Volatility,' specifically on the Sentiment Analysis and Stock Volatility portion of our project. </p>
<h2>Sentiment Analysis:</h2>
<p>Using the cleaned text data, we then conducted sentiment analysis on the news articles by using Vader from NLTK. Our plan was to calculate the sentiment score for each date in order to match them with the daily volatility data later on in our process. Therefore, the articles were sorted into ascending order of dates. However, we realized that the number of news articles that were scraped varied for each date. First, we attempted to summarize the news sentiment of each date by determining the average sentiment score for every article. Below shows the code snippet of our initial attempt: </p>
<div class="highlight"><pre><span></span><code><span class="c1"># Open the cleaned_data CSV file</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;final_data.csv&#39;</span><span class="p">)</span>


<span class="c1"># Calculate sentiment scores for each article</span>
<span class="n">sentiment_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">dates</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">SentimentIntensityAnalyzer</span><span class="p">()</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
   <span class="n">sentiment_score</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">polarity_scores</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">])[</span><span class="s1">&#39;compound&#39;</span><span class="p">]</span>
   <span class="n">sentiment_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentiment_score</span><span class="p">)</span>
   <span class="n">dates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])</span>


<span class="c1"># Create a DataFrame with the dates and sentiment scores</span>
<span class="n">sentiment_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">dates</span><span class="p">,</span> <span class="s1">&#39;sentiment_score&#39;</span><span class="p">:</span> <span class="n">sentiment_scores</span><span class="p">})</span>


<span class="c1"># Calculate average sentiment scores for each date</span>
<span class="n">average_sentiment_scores</span> <span class="o">=</span> <span class="n">sentiment_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;date&#39;</span><span class="p">)[</span><span class="s1">&#39;sentiment_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>


<span class="c1"># Convert date column to datetime format with specified format</span>
<span class="n">average_sentiment_scores</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">average_sentiment_scores</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">],</span> <span class="nb">format</span><span class="o">=</span><span class="s1">&#39;%m/</span><span class="si">%d</span><span class="s1">/%y&#39;</span><span class="p">)</span>


<span class="c1"># Sort the average sentiment scores DataFrame by date in ascending order</span>
<span class="n">average_sentiment_scores</span> <span class="o">=</span> <span class="n">average_sentiment_scores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>In general, the results showed that most of the positive event articles exhibited positive average sentiment scores, confirming that the event was indeed reflected in the news articles with positive sentiment. However, we acknowledged that the dataset was very limited in size, which was going to make it challenging to obtain reliable results in our regression analysis in the future. Consequently, instead of calculating the average for each date, we decided to calculate the individual sentiment scores from all the articles we had scraped, which provided us with a larger dataset to conduct our regression analysis. Below, we show the initial outcome of the average sentiment scores on the left-hand side, which consists of 16 datasets, and the updated sentiment score calculation on the right-hand side, which consists of 85 datasets. Another important point to mention is that in our first attempt, the date of the first news article was mistakenly recorded as July 6th instead of the correct date, which is July 9th. This happened because when we scraped the articles, some of them failed to process the dates and showed NaN, and we had to manually input the dates ourselves. We discovered this error and successfully incorporated the corrected date in our final version of the sentiment analysis. Then, we calculated the sentiment scores for the negative articles by applying the same method. Overall, the sentiment analysis process provided us with valuable lessons, such as the significance of dataset size and data quality control.</p>
<p><img alt="Picture showing average sentiment scores on the left-hand side, which consists of 16 datasets" src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/images/group-esg-and-volatility_02_lefthand-sentiment-score.jpg"></p>
<p><img alt="Picture showing updated sentiment score calculation on the right-hand side, which consists of 85 datasets" src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/images/group-esg-and-volatility_02_righthand-sentiment-score.jpg"></p>
<h2>Stock Volatility:</h2>
<p>While working on our project, we struggled to determine the best method to calculate and analyze the volatility in the best manner. In the beginning, our team considered using the traditional method of computing the annualized standard deviation of daily returns, which was the conventional approach to calculating volatility. The method was quite simple, but our existing dataset has data that is of a narrow time horizon. After reviewing extensive literature, we concluded that this method is used most of the time to study longer and fixed-time volatility conditions and may not be responsive to short-term sharp fluctuations. In our case, it may not be useful because our project is to capture rapid changes in volatility within a month of a news release.</p>
<p>To address the problem, we turn to the rolling volatility method. This method calculates the standard deviation of returns within a moving window, which is more sensitive to changes, suitable for short-term risk, and more in line with our project objectives. </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="nn">yf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;SBUX&#39;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s1">&#39;2018-04-01&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;2018-05-01&#39;</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;Returns&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Adj Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">pct_change</span><span class="p">()</span>

<span class="n">data</span><span class="p">[</span><span class="s1">&#39;Rolling_Volatility&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Returns&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">252</span><span class="p">)</span>

<span class="n">start_date</span> <span class="o">=</span> <span class="s1">&#39;2018-04-16&#39;</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="s1">&#39;2018-04-27&#39;</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">start_date</span><span class="p">:</span><span class="n">end_date</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Rolling_Volatility&#39;</span><span class="p">]]</span>

<span class="n">result</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rolling_volatility&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Calculated Rolling Volatility:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;SBUX_Rolling_Volatility_April_2018.csv&#39;</span>
<span class="n">result</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">index_label</span><span class="o">=</span><span class="s1">&#39;date&#39;</span><span class="p">)</span>

<span class="n">read_back_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data read from CSV:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">read_back_data</span><span class="p">)</span>
</code></pre></div>

<p>The Python code above showed how we calculated volatility when negative news occurred. We obtained historical stock data of Starbucks (ticker: SBUX) for the month of April 2018 using the “yfinance” library. From this data, daily returns were calculated based on the adjusted closing price of the stock. Then, using the returns, we computed rolling volatility for the 2-day window and then annualized it by multiplying it with the square root of 252 (the normal trading days in a year). We then screened the data by specifically filtering for the date range of April 16, 2018, to April 27, 2018, as this was the actual range of dates when the negative news had occurred. The column names of the generated data frame were then converted into lowercase for consistency. We displayed the rolling volatility of the returned results with a date range saved to the CSV file, “SBUX_Rolling_Volatility_April_2018.csv,” using the “date” column as an index. Lastly, this code read the saved CSV file back into a new data frame. Finally, it read the saved CSV file back into a new data frame to ensure that the data was stored properly and in the right format. Finally, it printed the data to display what it contained.</p>
<p>When computing rolling volatility, we broadened the data range to include more than just the specific period being analyzed. For example, we might collect a full month's worth of stock data, even if our focus is on a shorter timeframe. This approach helps address edge effects by ensuring that calculations at the boundaries of our dataset are not skewed due to insufficient data. This ensures better consistency and accuracy throughout the analysis period and is also a step towards statistical robustness. The "warm-up" period in our model ensures that from the start, the rolling window benefits from a sufficient quantity of data, thus mitigating any potential inaccuracies caused by a limited number of data points. By incorporating a broader dataset, this approach enhances the model's ability to estimate volatility more accurately and stabilizes the impact of market variability. </p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-04-29T22:07:00+08:00">Mon 29 April 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html#group-esg-volatility-ref">Group ESG & Volatility
                    <span class="superscript">3</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2024-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>