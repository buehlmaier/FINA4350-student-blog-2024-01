<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students 2024" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group TheWay, Progress Report, " />

<meta property="og:title" content="ESG Risk Levels and Score Prediction Using LLM (By &#34;TheWay&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/esg-risk-levels-and-score-prediction-using-llm-by-theway.html" />
<meta property="og:description" content="Author: Chau Cheuk Him, Hung Man Kay, Sean Michael Suntoso, Tai Ho Chiu Hero, Wong Ngo Yin In today&#39;s rapidly evolving investment landscape, Environmental, Social, and Governance (ESG) factors have gained significant recognition as key drivers of long-term value creation. According to Bloomberg Intelligence, a staggering 85% of investors agree …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2024" />
<meta property="og:article:author" content="FINA4350 Students 2024" />
<meta property="og:article:published_time" content="2024-04-30T14:00:00+08:00" />
<meta name="twitter:title" content="ESG Risk Levels and Score Prediction Using LLM (By &#34;TheWay&#34;) ">
<meta name="twitter:description" content="Author: Chau Cheuk Him, Hung Man Kay, Sean Michael Suntoso, Tai Ho Chiu Hero, Wong Ngo Yin In today&#39;s rapidly evolving investment landscape, Environmental, Social, and Governance (ESG) factors have gained significant recognition as key drivers of long-term value creation. According to Bloomberg Intelligence, a staggering 85% of investors agree …">

        <title>ESG Risk Levels and Score Prediction Using LLM (By &#34;TheWay&#34;)  · FINA4350 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/"><span class=site-name>FINA4350 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2024-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/esg-risk-levels-and-score-prediction-using-llm-by-theway.html">
                ESG Risk Levels and Score Prediction Using LLM (By "TheWay")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p><em>Author: Chau Cheuk Him, Hung Man Kay, Sean Michael Suntoso, Tai Ho Chiu Hero, Wong Ngo Yin</em></p>
<p>In today's rapidly evolving investment landscape, Environmental, Social, and Governance (ESG) factors have gained significant recognition as key drivers of long-term value creation. According to Bloomberg Intelligence, a staggering 85% of investors agree that incorporating ESG considerations can lead to superior returns, bolster portfolio resilience, and enhance fundamental analysis. Projections indicate that by 2030, ESG investing is expected to account for a substantial portion, approximately US$40 trillion or 25%, of the total projected assets under management worldwide. Recognising the significance of ESG in investment decision-making, we have embarked upon the development of an ESG risk levels predictor, aimed at assisting investors in making informed and responsible investment choices.</p>
<h2>1. Background Information</h2>
<h3>1.1. What are ESG scores and ESG risk levels?</h3>
<p>ESG scores and ESG risk levels are two distinct measures used to assess environmental, social, and governance (ESG) factors. ESG scores provide a comprehensive evaluation of a company's overall sustainability and responsible business practices, considering a wide range of ESG criteria. These scores reflect the company's commitment to sustainability and its ability to manage ESG risks and opportunities effectively. On the other hand, ESG risk levels focus specifically on quantifying the potential risks associated with a company's ESG practices, assessing factors such as carbon emissions, labor practices, and regulatory compliance. There are 5 ESG risk levels: “Negligible”, “Low”, “Medium”, “High” and “Severe”, which provide investors with an assessment of the potential downside risks. Due to this different objective, ESG score is not always correlate with ESG Risk Level. </p>
<h3>1.2. The Significance of ESG Scores and ESG Risk Levels</h3>
<p>Fund managers seeking to align their investment strategies with ESG principles often rely on ESG scores and risk level to identify potential investments for inclusion in ESG-focused exchange-traded funds (ETFs) and other sustainable investment products. Our ESG scores and risk levels predictor aims to leverage advanced data analytics and machine learning techniques to predict and generate accurate ESG scores and risk level for companies, empowering investors with valuable information for their investment decision-making processes.</p>
<h3>1.3. Benefits of ESG Risk Levels and ESG Score Predictor</h3>
<p>ESG risk levels and score predictors hold significant potential to revolutionise the investment landscape by providing investors with a reliable tool to evaluate the sustainability performance of companies. By harnessing the power of data analytics and machine learning algorithms, our predictor offers the following benefits:</p>
<ol>
<li>Enhanced Investment Decision-Making: Investors can make more informed choices by incorporating ESG scores into their investment analysis. Our predictor enables investors to identify socially responsible companies with strong sustainability practices, aligning their investments with their values.</li>
<li>Risk Mitigation: By evaluating a company's environmental and social practices, investors can identify potential risks, such as regulatory non-compliance or reputational damage. Our predictor assists in identifying companies with robust governance frameworks, thereby reducing investment risks.</li>
<li>Sustainable Impact: Through the promotion of ESG investing, our predictor contributes to the broader goal of driving positive change in corporate behaviour. By rewarding companies with strong ESG practices, investors can incentivise sustainable practices and foster a more responsible business environment.</li>
</ol>
<p>Therefore, we decided to develop models to predict ESG Risk Levels and ESG Score as our project.</p>
<h2>2. Data Gathering and Pre-processing</h2>
<p>We gather data from two different source. </p>
<ol>
<li><a href="https://www.kaggle.com/code/mauriciovellasquez/esg-risk-analysis-insights-from-s-p-500-companies">Table consist of ESG Risk Level and Score</a> </li>
<li><a href="https://www.kaggle.com/datasets/tpotterer/motley-fool-scraped-earnings-call-transcripts">Table consist of Earnings Call Transcript</a></li>
</ol>
<p>Firstly, we proceed by merging the data based on the Ticker and removing any rows that contain invalid or empty data before 2022. Subsequently, we eliminate the Q&amp;A section from the transcript to reduce its length. In order to further condense the transcript for analysis purposes, we employ ESG-BERT to classify sections that are relevant to environmental, social, and governance (ESG) topics. This process results in an average word count reduction from 3012 to 1298. Additionally, we employ stop-word removal and lemmatization techniques before splitting the data into test and train sets.</p>
<p>Upon examining the ESG score chart, we observe a left-skewed distribution, indicating that a larger number of companies possess lower ESG scores.</p>
<p><img alt="Data Distribution" src="images/TheWay_02_Img01_TestTrainDataDist.png" title="Data Distribution"></p>
<p>This data imbalance can introduce bias towards the majority class in our model. To address this concern, we employ class weighting techniques during the model development phase to mitigate the impact of this imbalance.</p>
<h2>3. Development with Different Base Model</h2>
<h3>3.1. ESG-Bert Fine-tuning</h3>
<h4>3.1.1. Motivation</h4>
<p>In this project, we actually focused on the BERT model for predicting ESG scores and risk levels.</p>
<p>One of the main advantages of using BERT is its relatively lower computational resource requirements compared to other well-known powerful models like ChatGPT and Llama. BERT's lightweight nature allows us to achieve optimal performance even with medium-range GPUs. In contrast, getting the full potential of ChatGPT or Llama would require significantly more resources, which is not feasible for us. This accessibility and efficient use of limited resources make BERT a more practical choice for us.</p>
<p>Besides, BERT's architecture is particularly well-suited for classification tasks, such as predicting ESG risk levels. It allows for straightforward application to classification problems, like predicting ESG risk levels in this project. In contrast, generative models like ChatGPT and Llama, despite their impressive capabilities, can be less intuitive for classification tasks due to their autoregressive nature.</p>
<p>Another reason to choose BERT is its proven effectiveness in a variety of NLP tasks. As an older model compared to Llama or ChatGPT (BERT was published in 2018), BERT has been widely adopted and successfully applied across numerous research projects, giving us confidence in its ability to deliver strong results for ESG prediction tasks.</p>
<p>Furthermore, there are already fine-tuned models specifically designed for ESG-related tasks. These models demonstrate the potential of BERT for addressing the unique challenges associated with predicting ESG scores and risk levels.</p>
<p>ESG-Bert is one of the fine-tuned model available online. It is a <strong>Classification</strong> Natural Language Processing model fine-tuned for dealing with ESG-related data <strong>classification</strong> tasks. We are trying to fine-tune this model with our dataset for predicting the ESG scores and ESG risk level. We believe this approach would yield the best results.</p>
<h4>3.1.2. Work Done</h4>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;nbroad/ESG-BERT&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
</code></pre></div>

<p>We load the pre-trained ESG-Bert model and set its classifier as above for classifying the ESG risk level. On the other hand, if we would like to predict ESG scores, we have to replace the classification head with a linear layer to a continuous value.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;nbroad/ESG-BERT&#39;</span><span class="p">)</span>

<span class="c1"># For regression, we need to remove the classification head that outputs logits for classes</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>

<p>We then proceed to fine-tune. As mentioned, we have to deal with the data imbalance case.</p>
<div class="highlight"><pre><span></span><code><span class="n">num_classes</span><span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">class_weights</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;esg_risk_level&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span><span class="k">for</span> <span class="n">iin</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="c1"># Explicitly define as floatclass_weights= class_weights/ class_weights.sum()* num_classes</span>
<span class="n">model</span><span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;nbroad/ESG-BERT&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="n">optimizer</span><span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
<span class="n">criterion</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">class_weights</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)))</span><span class="c1"># Ensure weights are on the correct device and float</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># Use &quot;cuda&quot; if you have GPU</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Training Loop</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">labels</span><span class="p">)</span>  <span class="c1"># Ensure logits are FloatTensor</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>

<h4>3.1.3. Model Setup With Class Weights to Handle Imbalance Data</h4>
<p>To handle the imbalance, we calculated class weights for each ESG risk level. This approach helps the model treat each risk level fairly during the training process by giving more importance to less frequent classes. Essentially, we're telling the model that it's just as crucial to learn from the rarer ESG risk levels as it is from the more common ones.</p>
<p>Another important aspect of our approach is the choice of the CrossEntropyLoss function. This loss function is specifically designed for multi-class classification problems, making it a suitable choice for predicting ESG risk levels. By incorporating class weights into the loss function, we further ensure that the model gives equal attention to all ESG risk levels during training, leading to a more accurate and well-rounded prediction capability.</p>
<h4>3.1.4. Findings</h4>
<p>Below is the performance of the fine-tuned ESG-Bert model. We also try the performance of the vanilla ESG-Bert model (without any fine-tuning) on our dataset to set a benchmark.</p>
<table>
<thead>
<tr>
<th>ESG risk level prediction accuracy</th>
<th>Vanilla ESG-Bert</th>
<th>Fine-tuned ESG-Bert</th>
</tr>
</thead>
<tbody>
<tr>
<td>Training data</td>
<td>27.8%</td>
<td>51.4%</td>
</tr>
<tr>
<td>Testing data</td>
<td>21.7%</td>
<td>46.4%</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>ESG score prediction on testing data</th>
<th>Vanilla ESG-Bert</th>
<th>Fine-tuned ESG-Bert</th>
</tr>
</thead>
<tbody>
<tr>
<td>MSE (Mean Squared Error)</td>
<td>452.555</td>
<td>62.933</td>
</tr>
<tr>
<td>MAE (Mean Absolute Error)</td>
<td>20.134</td>
<td>20.134</td>
</tr>
</tbody>
</table>
<p>We see an obvious improvement after fine-tuning, but the performance is a bit below our expectations. Despite the current accuracy not being exceptionally high, we believe the fine-tuned ESG-BERT model still holds a certain level of usefulness. The improvements over the vanilla model indicate that it has learned to adapt to our specific dataset and task. As we continue to refine our approach, with BERT or ESG-Bert, we expect the model's performance to improve, making it a valuable tool for predicting ESG risk levels and scores in the future.</p>
<h3>3.2. Llama-2 Fine-tuning</h3>
<h4>3.2.1. Motivation</h4>
<p>Llama2 is a collection of pre-trained and fine-tuned large language models developed by Meta AI and released in 2023. These models are freely available for both research and commercial use. Llama2 AI models possess the ability to perform diverse natural language processing tasks, ranging from text generation to programming code analysis.  <strong>Llama2 is one of the strong LLM models, has been in used for fine-tuning for a while and is widely acknowledged to be even more powerful than BERT in general.</strong> Therefore, we believe that utilising this model will yield significant results and valuable comparisons. As such, it is worthwhile to provide a more detailed account of our methods and the work we have undertaken.</p>
<p>We decided to use <em>Llama-2-7b-chat-hf</em>, the Llama-2 model with 7 billion parameters from HuggingFace for fine-tuning. There are versions with 13b and 70b parameters, which are much more powerful. However, since we have limited resources (GPU), we have to use this smaller model to try and compute everything in a reasonable runtime.</p>
<h4>3.2.2. Work Done</h4>
<p>To access the Llama-2 model, we have to do the following:</p>
<p>First, visit https://llama.meta.com/llama-downloads/ and request access to Meta Llama with our email address. After receiving the permission email, log in to Hugging Face account on the Llama-2 model page at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf, and request access to the model repository.</p>
<p>Once gained access to the model repository, set up the development environment by installing the Hugging Face Hub library. Run <code>pip install huggingface-hub</code> in the environment and authenticate the registered account by running <code>huggingface-cli login</code>. This will your account and grant you access to the Llama-2 model.</p>
<p>With these steps completed, we can finally access the model with this line of code:</p>
<div class="highlight"><pre><span></span><code><span class="n">base_model</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span>
</code></pre></div>

<p>We fine-tuned the Llama-2 model by the following approach:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">combine_question_answer</span><span class="p">(</span><span class="n">transcript_esg</span><span class="p">,</span> <span class="n">esg_risk_level</span><span class="p">):</span>
    <span class="n">system_msg</span> <span class="o">=</span> <span class="s2">&quot;&lt;&lt;SYS&gt;&gt;</span><span class="se">\n</span><span class="s2">&quot;</span> \
        <span class="o">+</span> <span class="s2">&quot;You are an rating agency. Your task is to predict the a company&#39;s ESG Risk Level from a meeting transcript.&quot;</span> \
        <span class="o">+</span> <span class="s2">&quot;You should evaluate the company&#39;s performance on Environmental, Social and Governance issues.&quot;</span> \
        <span class="o">+</span> <span class="s2">&quot;The possible Risk Levels, from low to high, are `Negligible`, `Low`, `Medium`, `High`, `Severe`.</span><span class="se">\n</span><span class="s2">&quot;</span> \
        <span class="o">+</span> <span class="s2">&quot;&lt;&lt;/SYS&gt;&gt;</span><span class="se">\n\n</span><span class="s2">&quot;</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;s&gt;[INST] </span><span class="si">{</span><span class="n">system_msg</span><span class="si">}</span><span class="s2">###Transcript: </span><span class="si">{</span><span class="n">transcript_esg</span><span class="si">}</span><span class="s2">###Risk Level: [/INST] `</span><span class="si">{</span><span class="n">esg_risk_level</span><span class="si">}</span><span class="s2">`&lt;/s&gt;&quot;</span>
    <span class="k">return</span> <span class="n">prompt</span>

<span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="n">combine_question_answer</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">transcript_esg</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">esg_risk_level</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div>

<p>The purpose of creating this prompt is to make it super easy for our model to understand its mission. It's like giving it a treasure map and a set of instructions to follow.</p>
<p>The <code>combine_question_answer</code> function is like a magical spell that mixes three essential ingredients:</p>
<ol>
<li><strong>System message</strong>: A friendly note that tells our model what it's supposed to do. It's like saying, "Hey buddy, you're a rating agency, and you need to figure out a company's ESG Risk Level from this meeting transcript. Oh, and here are the possible Risk Levels you can choose from!"</li>
<li><strong>Transcript</strong>: This is the treasure map! It's the meeting transcript that our language model have to use to complete its mission.</li>
<li><strong>Risk Level</strong>: This is the final destination, the X on the treasure map. It's where our model should place the predicted ESG Risk Level.</li>
</ol>
<p>By creating this fun and structured prompt, we're helping our language model learn more effectively and become a pro at predicting ESG Risk Levels from meeting transcripts. </p>
<p>We then utilised the QLoRA (Quantised Low Rank Adaptation) method for fine-tuning our model. This approach is a type of PEFT (Parameter Efficient Fine Tuning) technique, which focuses on minimising the number of trainable parameters within a neural network. By optimising memory usage, QLoRA significantly reduces the time required for training. This time-saving advantage enables us to advance our project efficiently, even under tight time constraints.</p>
<div class="highlight"><pre><span></span><code><span class="n">peft_params</span><span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
    <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">r</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
    <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>

<p>By fine-tuning the Llama-2 model in this manner, we can effectively compare its performance with that of our main project focus, the ESG-BERT model, to determine the more accurate and efficient solution for assessing ESG risk levels.</p>
<h4>3.2.3. Findings</h4>
<p>The training and testing accuracies achieved by the fine-tuned Llama-2 model stand at 40.3% and 29.5%, respectively. The ESG-BERT model has demonstrated superior performance with an exact same dataset. This is likely because we are using the "weakest" Llama-2 model, with the least number of parameters, due to our limited computational resources. This constraint creates a bottleneck, preventing us from further improving the model's performance. <strong>As a result, we decided not to proceed with ESG score prediction and stopped at this point.</strong></p>
<h3>3.3. BERT Fine-tuning</h3>
<h4>3.3.1. Motivation</h4>
<p>Since the performance of ESG-BERT is not yet optimal, and we believe that BERT models have the potential to yield good results, we have also decided to directly utilise BERT and fine-tune it for this project. </p>
<h4>3.3.2. Work done</h4>
<p>Here are the codes and parameters that we use.  </p>
<div class="highlight"><pre><span></span><code><span class="n">BASE_MODEL</span> <span class="o">=</span> <span class="s2">&quot;google-bert/bert-base-uncased&quot;</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">BASE_MODEL</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">BASE_MODEL</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;checkpoints/bert_finetuned_</span><span class="si">{</span><span class="n">timestamp</span><span class="si">}</span><span class="s2">/&quot;</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">logging_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="c1"># metric_for_best_model=&quot;mse&quot;,</span>
    <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">dataset_train</span><span class="p">,</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">dataset_val</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics_for_regression</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>

<p>The work flow is basically the same as how we fine-tune the ESG-BERT model. </p>
<h4>3.3.3. Findings</h4>
<p>After training the model, here is the result of the ESG Score and Risk Level predictor model in train and test dataset. On the best case scenario, <strong>we manage to train a model with accuracy rate of above 75% on train data and above 52% in test data, which is higher than random guess and ESG-BERT fine-tuning that only have 51% accuracy for ESG Risk Level.</strong> </p>
<p>We also noticed that the ESG score predictor is capped at 26. This might be due to the class imbalance that resulting in ESG score prediction by our model less likely to give score of higher than 26. With this, <strong>we calculate that our model can achieve MSE at 16.3790 and 27.7570</strong> for training and testing dataset respectively, <strong>which is also better than ESG-BERT fine-tuning</strong>.</p>
<p><img alt="Train Data Prediction" src="images/TheWay_02_Img02_TrainDataPred.png" title="Train Prediction Result">
<img alt="Test Data Orediction" src="images/TheWay_02_Img03_TestDataPred.png" title="Test Prediction Result"></p>
<h2>4. Deployment</h2>
<p>Since we think that deploying the model to visualise the result would make the presentation more appealing than plain code, we deployed our model using Python Flask. </p>
<p>At first, the deployment model do not have a very friendly GUI. It contains only one input field and returns a JSON string after <code>Search</code> is clicked. </p>
<h3>4.1. Original GUI</h3>
<p><img alt="Original GUI" src="images/TheWay_02_Img04_OriGUI.png"></p>
<p><img alt="Original GUI" src="images/TheWay_02_Img05_OriGUI.png"></p>
<h3>4.2. What we want to achieve</h3>
<p>We have had some discussions and think that a GUI that looked like this would look better.</p>
<p><img alt="Design" src="images/TheWay_02_Img06_GUI.png"></p>
<h3>4.3. Leveraging GenAI</h3>
<p>So we put both our code + the image above into ChatGPT, and asked how we could use Bootstrap to create a GUI like the image as shown above. </p>
<ul>
<li>
<p>Conversation with ChatGPT</p>
<p><img alt="ChatGPT" src="images/TheWay_02_Img07_Chat.png">
<img alt="ChatGPT" src="images/TheWay_02_Img08_Chat.png">
<img alt="ChatGPT" src="images/TheWay_02_Img09_Chat.png"></p>
</li>
</ul>
<p>After prompt engineering and finetuning the code provided, we refined the GUI. Also, we added the “Download Data” function so that users can download the predicted esg risk level, esg score, and ESG-related transcript into a .txt file for further processing. </p>
<p><img alt="Deploy GUI" src="images/TheWay_02_Img10_Deploy.png"></p>
<ol>
<li>Run the python server </li>
</ol>
<div class="highlight"><pre><span></span><code>python ./{directory}/deploy_model.py 
</code></pre></div>

<ol>
<li>Open the HTML file <code>index.html</code></li>
</ol>
<p><img alt="Deployment Details" src="images/TheWay_02_Img11_Deploy.png"></p>
<p>Below is the workflow of the deployment: </p>
<p>Case I: User enters a stock symbol in the HTML form and clicked <code>Search</code>: </p>
<ol>
<li>JavaScript Handling:
Captures the form submission and prevents default submission, sends a AJAX request with the symbol to Flask server</li>
<li>Python (Flask) Processing:
Receives AJAX request -&gt; Searches in our predicted risk level.csv (which is the saved output result from the previous process)  -&gt; Sends back response (ESG data or error message) -&gt;</li>
<li>
<p>JavaScript Updates HTML:</p>
<p>Receives response from Flask server -&gt; Updates HTML to display ESG data or an error message -&gt; If data received, shows download button </p>
</li>
</ol>
<p>Case II: User clicks the <code>Download</code> : </p>
<ol>
<li>User clicks download button -&gt; JavaScript triggers file download</li>
</ol>
<h2>5. Summary</h2>
<p>In this blog post, we discuss our findings and experiences in developing a good model to predict ESG risk levels by fine-tuning ESG-BERT, Llama2 and BERT. We discovered that directly fine-tuning the BERT model yielded even more promising results than fine-tuning the ESG-BERT model, which was initially expected to perform better on ESG-related tasks. As a result, we suggest focusing on this direction in future work.</p>
<p>And to make the presentation more appealing and showcase the results effectively, we deployed our model using Python Flask. This approach allowed us to visualise the results in a more interactive and user-friendly manner compared to plain code.</p>
<p>One challenge we faced was the limited performance of the Llama2 version feasible to us. Computational resources proved to be a significant issue when working on this project.</p>
<p>For future work, we aim to improve the accuracy of our model using BERT as the base model. To achieve this, we propose the following enhancements:</p>
<ul>
<li>Expanding the dataset to include more companies and years of transcripts</li>
<li>Incorporating additional data sources such as news articles and media coverage</li>
<li>Conducting advanced feature engineering to explore and create additional relevant features</li>
<li>Leveraging domain knowledge and external data sources to enrich the feature set</li>
</ul>
<p>By implementing these improvements, we hope to develop a more robust and accurate ESG risk level prediction model, ultimately providing investors with a valuable tool for evaluating companies' sustainability performance.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-04-30T14:00:00+08:00">Tue 30 April 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html#group-theway-ref">Group TheWay
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2024-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>