<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students 2024" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group Textonomy, Reflection Report, " />

<meta property="og:title" content="Blog Post Two - Encounter, Analyze, and Solve (by Group &#34;Textonomy&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/blog-post-two-encounter-analyze-and-solve-by-group-textonomy.html" />
<meta property="og:description" content="As we are all new to NLP and related techniques, we believe sharing the challenges we met along the way is valuable. We hope these experiences can serve as a reference for future NLP learners. Data Collection and Preprocessing (by Zepa) In the data processing part for pre-training data, our …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2024" />
<meta property="og:article:author" content="FINA4350 Students 2024" />
<meta property="og:article:published_time" content="2024-04-30T22:30:00+08:00" />
<meta name="twitter:title" content="Blog Post Two - Encounter, Analyze, and Solve (by Group &#34;Textonomy&#34;) ">
<meta name="twitter:description" content="As we are all new to NLP and related techniques, we believe sharing the challenges we met along the way is valuable. We hope these experiences can serve as a reference for future NLP learners. Data Collection and Preprocessing (by Zepa) In the data processing part for pre-training data, our …">

        <title>Blog Post Two - Encounter, Analyze, and Solve (by Group &#34;Textonomy&#34;)  · FINA4350 Student Blog 2024
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2024 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/"><span class=site-name>FINA4350 Student Blog 2024</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2024-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/blog-post-two-encounter-analyze-and-solve-by-group-textonomy.html">
                Blog Post Two - Encounter, Analyze, and Solve (by Group "Textonomy")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>As we are all new to NLP and related techniques, we believe sharing the challenges we met along the way is valuable. We hope these experiences can serve as a reference for future NLP learners.</p>
<h2>Data Collection and Preprocessing (by Zepa)</h2>
<p>In the data processing part for pre-training data, our group has adopted data from 3 sources, namely <strong>Financial phrasebank</strong> (financial news headings and sentiments), <strong>Sanders</strong> (Twitter sentiment corpus), and <strong>Taborda</strong> (stock market tweets data). </p>
<p>One challenge here is that our group needs to select accurate, relevant, and useful data, and it will be best if those data are well-packed, cleaned, and tidied up already. Our group spent a certain amount of time selecting high-quality data input to ensure potentially high-quality output.</p>
<p>Another little challenge here is that there may be an extra space at the last line of each individual processed sentence due to the usage of <code>\n</code>, which is undesired, so our group modified the previous code of <code>code_taborada.py</code> and utilized the <code>if-else</code> statement to specifically make it excluded. Below is an example from <code>code_taborada.py</code>.</p>
<p><img alt="code snippet in code_taborada.py" src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/images/Textonomy_02_code-snippet.png"></p>
<h2>Model Training (By Bosco)</h2>
<p>In this part, I will illustrate the challenges I face when training our BERT model with reference to the <a href="https://www.tensorflow.org/text/tutorials/classify_text_with_bert">"Classify text with BERT"</a> tutorial on TensorFlow.</p>
<p>The most challenging part is to read the dataset in python, which was collected and preprocessed by Zepa. Zepa combined the three datasets and transformed them into one consistent format, which consists of some lists of <code>[sentence, label]</code>. The dataset is then exported as a <code>.txt</code> file for later use. My job is to read the text file in Python and use the data to train the BERT model. Below is the code I used to read the lines:</p>
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;combined_result.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
        <span class="c1"># Remove leading and trailing whitespace and newline character</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="c1"># Remove the square brackets</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">)</span>
        <span class="c1"># Find the index of the last comma in the line</span>
        <span class="n">last_comma_index</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rindex</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
        <span class="n">sentence</span> <span class="o">=</span> <span class="n">line</span><span class="p">[:</span><span class="n">last_comma_index</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">label</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="n">last_comma_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">strip</span><span class="p">())</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">sentence</span><span class="p">,</span> <span class="n">label</span><span class="p">])</span>
</code></pre></div>

<p>The code assumes that each line in the text file is in the form of <code>[sentence, label]</code>. It then proceeds to find the position of the last comma. Everything before the last comma is assigned to the sentence variable, and the integer after the last comma represents the label. One can easily extract the  i<sup>th</sup> sentence by <code>data[i][0]</code> and the  i<sup>th</sup> label by <code>data[i][1]</code>. The code functions effectively when the dataset is in a consistent format. I test the code with just one dataset and it works well. However, when I test it with the combined dataset, it is not the case. After some eyeball checking, it may be due to some occasional gaps within the list that are caused by some bugs on Zepa's part. To resolve this issue, I tried deleting the gaps manually, but the sample size is large, so that this method is quite inefficient.</p>
<p><img alt="example of special cases" src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/images/Textonomy_02_special-cases.png"></p>
<p>Finally, I came up with a solution, which is to add a line of code: <code>match = re.match(r'^(.+?),\s*(\d+)$', line)</code>, which can validate and extract the relevant information from each line. </p>
<ul>
<li><code>^</code>: Anchors the pattern to the start of the string.</li>
<li><code>(.+?)</code>: Matches and captures one or more characters (except a newline) lazily. The <code>+</code> indicates one or more occurrences, and the <code>?</code> makes the matching lazy, meaning it captures as few characters as possible.</li>
<li><code>,</code>: Matches a comma character.</li>
<li><code>\s*</code>: Matches zero or more whitespace characters. The <code>\s</code> represents any whitespace character (spaces, tabs, etc.), and the <code>*</code> indicates zero or more occurrences.</li>
<li><code>(\d+)</code>: Matches and captures one or more digits. The <code>\d</code> represents any digit character (0-9), and the <code>+</code> indicates one or more occurrences.</li>
<li><code>$</code>: Anchors the pattern to the end of the string.</li>
</ul>
<p>The <code>re.match()</code> function is used to check whether the line matches the specified pattern. If and only if a match is found, the code proceeds to extract the sentence and label. As a result, any lines with anomalies are ignored. However, two new issues have arisen. </p>
<p>Firstly, there are some lines that match the specified pattern, but they do not actually represent the desired sample data and have been mistakenly included in the dataset. Fortunately, there are only a few lines with this issue, and it can be resolved manually.</p>
<p><img alt="example of special cases 2" src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/images/Textonomy_02_special-cases-2.png"></p>
<p>Another issue is that the code can only read the lines after the gap in those gapped lists, as the lines before the gap do not match the expected format. There are numerous lines affected by this problem, and due to time constraints, I have decided to retain them in the dataset. I believe that including this noise data might potentially improve the training process. </p>
<p>Nonetheless, if time permits, we aim to address the issue at its root cause, which is the data preprocessing stage. Our goal is to ensure the dataset is consistent and properly formatted, thereby eliminating the need to handle inconsistencies during the training process.</p>
<h2>Web Scraping and Result Analysis (By Marcel, Wenkai, and Wanqian)</h2>
<p>In order to get current text data to use for our sentiment analysis, we decided to scrape the <a href="https://news.search.yahoo.com/search?p=search_example">Yahoo Finance search site</a>. For that, we used a set of AI-related keywords.</p>
<p>A few challenges arose during web scraping development:
- (presumably) temporary IP blocking
- duplicate data
- imprecise datetime values in text format.</p>
<p>We started testing our scraper by running the scraping functions in a for loop for each keyword, trying to maximize AI-related news data. We noticed that the csv files we put the date in were alternating between having no data whatsoever and having (expected) hundreds to thousands of news entries. The pattern suggested a temporary inability to access the search site which we assumed to be due to temporary IP blocking. Our solution to this problem was to implement a timer that waits after each scraping iteration by keyword before starting the next iteration, which solved this issue. Considerations for a more sophisticated solution in the future are using proxy servers or rotating IPs and adjusting the timer dynamically based on the server’s response (minimizing the timer duration).</p>
<p>As all keywords are related to each other (because we were using AI-related keywords) and because we were scraping every day to get the newest data, naturally, we expected duplicate data. To solve this we developed scripts that would parse the data of the different keywords and combine it into a combined file while eliminating duplicates, as well as add the newest distinct data to these files every day. </p>
<p>Lastly, the search site did not return actual datetime values for the post date of the articles but returned text values such as “3 days ago”, “45 minutes ago”, and “1 week ago”. The higher the aggregation level of this time information, the more imprecise a conversation to a datetime value was. Example: If we have a data entry saying the post was released 45 minutes ago, we can parse it into a datetime value that is <code>now() - 45 minutes</code>, meaning the exact value would only be off by seconds. 
However, for values where the date posted was “2 weeks ago”, <code>now() - 2 weeks</code> could potentially be off by days, making these data points less helpful.</p>
<p>When using the scraped data for analysis, the datetime imprecision problem got worse. The target AI index we analyzed was a US index, and we needed to further convert the time into Eastern Time. Therefore, we cannot guarantee that the news was published on that day. For example, we scraped data at 12:30 P.M. on April 20th and one piece of news showed “one day ago.” We then assumed the news was published at 12:30 P.M. on April 19th in Hong Kong time, and therefore, 12:30 A.M. on April 19th in  Eastern Time. But the news could be published at night on April 18th in Eastern Time.</p>
<p>Despite the time imprecision, we also encountered data imbalance. The Yahoo Finance website tends to return more news published recently and less old news. Therefore, the sentiment scores may be less accurate for long ago dates due to inadequate data, while it takes more computing resources to produce sentiment scores for recent dates with thousands of pieces of news. However, this problem will diminish in the long run as we will collect more and more data.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2024-04-30T22:30:00+08:00">Tue 30 April 2024</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/categories.html#reflection-report-ref">Reflection Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/tags.html#group-textonomy-ref">Group Textonomy
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2024-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2024-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>